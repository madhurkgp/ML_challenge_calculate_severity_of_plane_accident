{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip uninstall numpy --yes\n",
    "# !pip install numpy==1.16.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "# from catboost import CatBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import lightgbm as lgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def min_max(x,minx,maxx):\n",
    "# #     print(x.mean())\n",
    "#     return (x-minx)/(maxx-minx)\n",
    "\n",
    "# def standardscale(x,meanx,stdx):\n",
    "#     return (x-meanx)/stdx\n",
    "\n",
    "# minx = df['Safety_Score'].min()\n",
    "# maxx = df['Safety_Score'].max()\n",
    "# df['Safety_Score'] = df['Safety_Score'].apply(min_max, args=(minx,maxx) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv',sep=',')\n",
    "df.drop(['Accident_ID'],inplace=True,axis=1)\n",
    "test_df = pd.read_csv('test.csv',sep=',')\n",
    "test_df_accident = test_df[['Accident_ID']]\n",
    "test_df.drop('Accident_ID',inplace=True,axis=1)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Severity'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "severity_label_mapping = {'Highly_Fatal_And_Damaging': 3,\n",
    "'Significant_Damage_And_Serious_Injuries': 2,\n",
    "'Minor_Damage_And_Injuries': 0,\n",
    "'Significant_Damage_And_Fatalities': 1\n",
    "}\n",
    "df[\"Severity\"] = df[\"Severity\"].map(severity_label_mapping).astype(np.int32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for col in df.columns:\n",
    "#     print(df[col].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"darkgrid\")\n",
    "ax = sns.countplot(x=\"Severity\",hue='Accident_Type_Code', data=df,orient='v')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_2 = \n",
    "print(df.groupby('Severity')['Safety_Score'].mean())\n",
    "print('\\n-----------------------------------------------\\n')\n",
    "print(df.groupby('Severity')['Days_Since_Inspection'].mean())\n",
    "print('\\n-----------------------------------------------\\n')\n",
    "print(df.groupby('Severity')['Total_Safety_Complaints'].mean())\n",
    "print('\\n-----------------------------------------------\\n')\n",
    "print(df.groupby('Severity')['Control_Metric'].mean())\n",
    "print('\\n-----------------------------------------------\\n')\n",
    "print(df.groupby('Severity')['Turbulence_In_gforces'].mean())\n",
    "print('\\n-----------------------------------------------\\n')\n",
    "print(df.groupby('Severity')['Cabin_Temperature'].mean())\n",
    "print('\\n-----------------------------------------------\\n')\n",
    "print(df.groupby('Severity')['Max_Elevation'].mean())\n",
    "print('\\n-----------------------------------------------\\n')\n",
    "print(df.groupby('Severity')['Violations'].mean())\n",
    "print('\\n-----------------------------------------------\\n')\n",
    "print(df.groupby('Severity')['Adverse_Weather_Metric'].mean())\n",
    "\n",
    "# df.groupby(['id','mth'])['cost'].sum()\n",
    "\n",
    "# df_2.reset_index(inplace=True)\n",
    "# sns.barplot(x='A', y='B', data=df_2);\n",
    "# df_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def min_max(x,minx,maxx):\n",
    "# #     print(x.mean())\n",
    "#     return (x-minx)/(maxx-minx)\n",
    "\n",
    "# def standardscale(x,meanx,stdx):\n",
    "#     return (x-meanx)/stdx\n",
    "\n",
    "# df['Safety_Score'] = df['Safety_Score'].apply(standardscale, args=(df['Safety_Score'].mean(),df['Safety_Score'].std()))\n",
    "# df['Days_Since_Inspection'] = df['Days_Since_Inspection'].apply(min_max, args=(df['Days_Since_Inspection'].min(),df['Days_Since_Inspection'].max()) )\n",
    "# df['Total_Safety_Complaints'] = df['Total_Safety_Complaints'].apply(min_max, args=(df['Total_Safety_Complaints'].min(),df['Total_Safety_Complaints'].max()) )\n",
    "# df['Control_Metric'] = df['Control_Metric'].apply(standardscale, args=(df['Control_Metric'].mean(),df['Control_Metric'].std()))\n",
    "# df['Turbulence_In_gforces'] = df['Turbulence_In_gforces'].apply(min_max, args=(df['Turbulence_In_gforces'].min(),df['Turbulence_In_gforces'].max()) )\n",
    "# df['Cabin_Temperature'] = df['Cabin_Temperature'].apply(min_max, args=(df['Cabin_Temperature'].min(),df['Cabin_Temperature'].max()) )\n",
    "# df['Accident_Type_Code'] = df['Accident_Type_Code'].apply(min_max, args=(df['Accident_Type_Code'].min(),df['Accident_Type_Code'].max()) )\n",
    "# df['Max_Elevation'] = df['Max_Elevation'].apply(standardscale, args=(df['Max_Elevation'].mean(),df['Max_Elevation'].std()))\n",
    "# df['Violations'] = df['Violations'].apply(min_max, args=(df['Violations'].min(),df['Violations'].max()) )\n",
    "# df['Adverse_Weather_Metric'] = df['Adverse_Weather_Metric'].apply(min_max, args=(df['Adverse_Weather_Metric'].min(),df['Adverse_Weather_Metric'].max()) )\n",
    "\n",
    "\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_columns = ['Safety_Score', 'Days_Since_Inspection', 'Total_Safety_Complaints', 'Control_Metric',\n",
    "             'Turbulence_In_gforces', 'Cabin_Temperature', 'Accident_Type_Code',\n",
    "             'Max_Elevation', 'Violations', 'Adverse_Weather_Metric']\n",
    "\n",
    "y_columns = ['Severity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y = df[['Severity']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['Severity'], axis = 1) \n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# x_train, x_test, y_train, y_test = train_test_split(X,Y,test_size=0.3,random_state=0,stratify=Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# x_train = scaler.fit_transform(x_train)\n",
    "# x_test = scaler.transform(x_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "class_weights = list(class_weight.compute_class_weight('balanced',\n",
    "                                             np.unique(Y['Severity']),\n",
    "                                             Y['Severity']))\n",
    "\n",
    "w_array = np.ones(Y.shape[0], dtype = 'float')\n",
    "for i, val in enumerate(Y.values):\n",
    "#     print(i,val)\n",
    "    w_array[i] = class_weights[int(val)-1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "clf = XGBClassifier(eta = 0.01, max_depth=10, objective='multi:softmax', n_estimators=1000, \n",
    "                        num_classes=4, random_state=0, n_jobs=3, sample_weight=w_array)\n",
    "# clf.fit(x_train,y_train)\n",
    "clf.fit(X,Y)\n",
    "\n",
    "# clf.feature_importances_\n",
    "for foo,bar in zip(x_columns,clf.feature_importances_):\n",
    "    print(foo,bar*100)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# RF = RandomForestClassifier(n_estimators=1000, random_state=0).fit(X, Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "params = {\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'multiclass',\n",
    "    'num_class': 4,\n",
    "    'metric': 'multi_logloss'\n",
    "\n",
    "}\n",
    "lgb_train = lgb_train = lgb.Dataset(X,Y)\n",
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_keras = Sequential()\n",
    "model_keras.add(Dense(8, input_dim=10, activation='relu'))\n",
    "model_keras.add(Dense(7, activation='relu'))\n",
    "model_keras.add(Dense(6, activation='relu'))\n",
    "model_keras.add(Dense(5, activation='relu'))\n",
    "model_keras.add(Dense(4, activation='softmax'))\n",
    "# Compile model\n",
    "model_keras.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model_keras.fit(X, to_categorical(Y),batch_size=10,epochs=1000,verbose=1,shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_df = scaler.transform(test_df.values)\n",
    "y_test_xgb = clf.predict(test_df)\n",
    "\n",
    "y_test_keras = model_keras.predict(test_df)\n",
    "y_test_keras_np = np.argmax(y_test_keras, axis=1)\n",
    "\n",
    "# y_test_rf = RF.predict(test_df)\n",
    "\n",
    "y_test_lgbm = gbm.predict(test_df, num_iteration=gbm.best_iteration)\n",
    "y_test_lgbm = np.argmax(y_test_lgbm, axis=1)\n",
    "\n",
    "# y_test_lr = model_lr.predict(test_df)\n",
    "# print(\"Accuracy: \", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_df_accident['Severity_xgb'] = y_test_xgb\n",
    "\n",
    "test_df_accident['Severity_keras'] = y_test_keras_np\n",
    "# test_df_accident['Severity_rf'] = y_test_xgb\n",
    "test_df_accident['Severity_lgbm'] = y_test_lgbm\n",
    "# test_df_accident['Severity_lr'] = y_test_lr\n",
    "\n",
    "# test_df_accident"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test_df_accident['change'] = np.logical_xor(test_df_accident['Severity_xgb'].values,test_df_accident['Severity_lr'].values)\n",
    "# test_df_accident['change'] = np.where((test_df_accident['Severity_xgb'] != test_df_accident['Severity_lgbm']), True, False)\n",
    "\n",
    "test_df_accident.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test_df_accident[test_df_accident['change']==True]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test_df_accident.index[test_df_accident['change'] == True].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# change_df = test_df_accident[test_df_accident['change']==True]\n",
    "# change_df.groupby(['Severity_xgb','Severity_lgbm']).size().reset_index().rename(columns={0:'count'})\n",
    "\n",
    "# xgb\tkeras\tcount\n",
    "# 0\t0\t1\t2\n",
    "# 1\t0\t2\t12\n",
    "# 2\t0\t3\t13\n",
    "# 3\t1\t0\t3\n",
    "# 4\t2\t0\t6\n",
    "# 5\t3\t0\t3\n",
    "\n",
    "\n",
    "# Severity_xgb\tSeverity_lgbm\tcount\n",
    "# 0\t0\t1\t2\n",
    "# 1\t0\t2\t4\n",
    "# 2\t0\t3\t5\n",
    "# 3\t1\t0\t2\n",
    "# 4\t2\t0\t1\n",
    "# 5\t3\t0\t2\n",
    "\n",
    "# [268,352, 779, 869, 1048,\n",
    "#  1080,1135,1286,1329,1904,\n",
    "#  2002,2063,2090,2238,2405,2438]\n",
    "\n",
    "\n",
    "#  5 -> 10 xgbbost \n",
    "# Severity_xgb\tSeverity_lgbm\tcount\n",
    "# 0\t0\t1\t2\n",
    "# 1\t0\t2\t4\n",
    "# 2\t0\t3\t8\n",
    "# 3\t1\t0\t2\n",
    "# 4\t2\t0\t7\n",
    "# 5\t3\t0\t3\n",
    "\n",
    "# [105, 218, 268,352, 412, 858,\n",
    "#  892, 1080, 1116, 1118, 1135, 1286,\n",
    "#  1291, 1329, 1507, 1720, 1755, 1784,\n",
    "#  1870, 2002, 2061, 2192, 2238, 2405,\n",
    "#  2438, 2467]\n",
    "\n",
    "#lgbm - iteration 1000\n",
    "# [30, 302, 352, 869, 892, 927, 1118,\n",
    "#  1291, 1507,1720, 1784,\n",
    "#  1870, 2063, 2192, 2405, 2467]\n",
    "\n",
    "# Severity_xgb\tSeverity_lgbm\tcount\n",
    "# 0\t0\t1\t2\n",
    "# 1\t0\t3\t3\n",
    "# 2\t1\t0\t2\n",
    "# 3\t2\t0\t6\n",
    "# 4\t3\t0\t3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_df_accident.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "severity_label_mapping_reverse = {3:'Highly_Fatal_And_Damaging',\n",
    "                                  2:'Significant_Damage_And_Serious_Injuries',\n",
    "                                  0:'Minor_Damage_And_Injuries',\n",
    "                                  1:'Significant_Damage_And_Fatalities'}\n",
    "\n",
    "test_df_accident[\"Severity_lgbm\"] = test_df_accident[\"Severity_lgbm\"].map(severity_label_mapping_reverse)\n",
    "test_df_accident[\"Severity_xgb\"] = test_df_accident[\"Severity_xgb\"].map(severity_label_mapping_reverse)\n",
    "test_df_accident[\"Severity_keras\"] = test_df_accident[\"Severity_keras\"].map(severity_label_mapping_reverse)\n",
    "\n",
    "test_df_accident.head(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "t = time.localtime()\n",
    "timestamp = time.strftime('%b-%d-%Y_%H%M', t)\n",
    "\n",
    "test_df_accident.to_csv(f'output_lgbm_{timestamp}.csv',index=False,columns=['Accident_ID','Severity_lgbm'])\n",
    "test_df_accident.to_csv(f'output_xgb_{timestamp}.csv',index=False,columns=['Accident_ID','Severity_xgb'])\n",
    "test_df_accident.to_csv(f'output_keras_{timestamp}.csv',index=False,columns=['Accident_ID','Severity_keras'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.describe()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "check_df = pd.read_csv('test.csv',sep=',')\n",
    "\n",
    "check_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "check_df[check_df['Accident_ID'].isin([190,265,1473,1804,1941])]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "check_df.describe()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
